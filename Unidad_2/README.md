
# Unidad 2: AdquisiciÃ³n, Ingesta y Procesamiento de Datos ğŸ“¡

![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?logo=numpy&logoColor=white)
![Spark](https://img.shields.io/badge/Spark-FDEE21?logo=apachespark&logoColor=black)
![Kafka](https://img.shields.io/badge/Kafka-231F20?logo=apachekafka&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4B8BBE?logo=python&logoColor=white)
![Selenium](https://img.shields.io/badge/Selenium-43B02A?logo=selenium&logoColor=white)
![API](https://img.shields.io/badge/API-FF9800?logo=apachespark&logoColor=black)
![Flink](https://img.shields.io/badge/Flink-EA4335?logo=apacheflink&logoColor=white)
![Airflow](https://img.shields.io/badge/Airflow-017CEE?logo=apacheairflow&logoColor=white)

---

## âš¡ Objetivos EspecÃ­ficos

- Aplicar **tÃ©cnicas y metodologÃ­as** para la adquisiciÃ³n, ingesta y procesamiento eficiente de grandes volÃºmenes de datos provenientes de fuentes diversas.
- Garantizar la **calidad, integridad y pertinencia** de los datos para su anÃ¡lisis posteriorğŸ“Š.
- Distinguir entre **procesamiento batch** y **procesamiento en tiempo real**ğŸ”„.
- Implementar **flujos de procesamiento distribuido** empleando herramientas especializadas para la limpieza y transformaciÃ³n de datos.

---

## ğŸ… Competencias EspecÃ­ficas a Desarrollar

- Investigar y comparar **mÃ©todos de adquisiciÃ³n e ingesta de datos**, incluyendo tÃ©cnicas de web scraping, consumo de APIs y sistemas de ingesta en tiempo realğŸ’¡.
- Identificar y documentar **fuentes de datos** (estructurados, semiestructurados y no estructurados) relevantes para proyectos de Big Data.
- Desarrollar prÃ¡cticas de **extracciÃ³n y procesamiento** de datos utilizando herramientas como BeautifulSoup, Pandas, NumPy y KafkağŸ”¬.
- Analizar y diferenciar los **paradigmas batch vs. streaming**, determinando casos de aplicaciÃ³n para cada uno.
- Aplicar tÃ©cnicas de **preprocesamiento**: normalizaciÃ³n, imputaciÃ³n y detecciÃ³n de outliers usando Python y sus principales librerÃ­asğŸ§¹.

---

## ğŸ–¥ï¸ TecnologÃ­as principales en la unidad

- Web scraping: **BeautifulSoup**, **Selenium**
- APIs pÃºblicas: **REST**, **Twitter API**, **Google Maps API**
- Ingesta en tiempo real: **Kafka**, **Flume**, **NiFi**, **Airflow**
- Procesamiento distribuido: **Spark**, **Flink**, **Storm**

---

## ğŸ“š Actividades de aprendizaje recomendadas

- Investigar y comparar mÃ©todos de adquisiciÃ³n e ingesta de datos.
- Documentar fuentes relevantes para proyectos de Big Data.
- Practicar extracciÃ³n de datos mediante web scraping y consumo de APIs pÃºblicas.
- Desarrollar ejercicios de ingesta en tiempo real con herramientas especializadas.
- Analizar diferencias entre procesamiento batch y streaming.
- Elaborar reportes tÃ©cnicos sobre calidad de datos y mejores prÃ¡cticas.
- Participar en casos prÃ¡cticos de integraciÃ³n y procesamiento colaborativo.

---

## ğŸ¤ Soft Skills y competencias genÃ©ricas reforzadas

- AnÃ¡lisis y sÃ­ntesis de informaciÃ³n
- OrganizaciÃ³n y planificaciÃ³n de proyectos
- ComunicaciÃ³n oral y escrita
- Trabajo colaborativo en equipos multidisciplinares
- Pensamiento crÃ­tico y resoluciÃ³n de problemas

---

> ğŸš¦ **Recuerda:** Esta unidad te prepara para manejar cualquier tipo de fuente de datos y optimizar el flujo de procesamiento desde la adquisiciÃ³n hasta la limpieza, asegurando datos confiables para cualquier anÃ¡lisis avanzado.

